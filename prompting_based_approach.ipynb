{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Context & Few-shot Learning with Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages & environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from IPython.display import HTML\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Let's prepare 15 train instances for the few shot learning & 10 test instances for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CONVFINQA/data/train.json') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_list = []\n",
    "for entry in train_data[:15]:\n",
    "    table = entry['annotation']['amt_table']\n",
    "    question_sequence = entry['annotation']['dialogue_break']\n",
    "    turn_program = entry['annotation']['turn_program']\n",
    "    \n",
    "    follow_up_questions = ''\n",
    "    \n",
    "    for i in range(len(question_sequence)-1):\n",
    "        follow_up_questions += f'Intermediate Question: {question_sequence[i]}\\n'\n",
    "        follow_up_questions += f'Intermediate Solution/Turn Program: {turn_program[i]}\\n'\n",
    "\n",
    "    train_list.append({\n",
    "        'context': table,\n",
    "        'questions': follow_up_questions,\n",
    "        'last_question': question_sequence[-1],\n",
    "        'answer': turn_program[-1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CONVFINQA/data/test_private.json') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "def generate_wiki_table(table_data):\n",
    "    # Initialize the wiki table string\n",
    "    wiki_table = \"<table class='wikitable'>\"\n",
    "\n",
    "    # Iterate over each row in the table data\n",
    "    for row in table_data:\n",
    "        wiki_table += \"<tr>\"\n",
    "        # Iterate over each cell in the row\n",
    "        for cell in row:\n",
    "            wiki_table += f\"<td>{cell}</td>\"\n",
    "        wiki_table += \"</tr>\"\n",
    "\n",
    "    # Close the table tag\n",
    "    wiki_table += \"</table>\"\n",
    "\n",
    "    return wiki_table\n",
    "\n",
    "test_list = []\n",
    "for entry in test_data[:10]:\n",
    "    table = generate_wiki_table(entry['table'])\n",
    "    question_sequence = entry['annotation']['dialogue_break']\n",
    "\n",
    "    follow_up_questions = ''\n",
    "    \n",
    "    for i in range(len(question_sequence)-1):\n",
    "        follow_up_questions += f'Intermediate Question: {question_sequence[i]}\\n'\n",
    "\n",
    "    last_question = question_sequence[-1]\n",
    "\n",
    "    test_list.append({\n",
    "        'context': table,\n",
    "        'questions': follow_up_questions,\n",
    "        'last_question': last_question\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt to Try the Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'turn program: \\n\\nsubtract(206588, 181001) / 181001 * 100'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"questions\", \"last_question\"],\n",
    "    template = \"Instruction: I am a highly intelligent bot. I can have conversations with the user to answer a series of questions.\\\n",
    "Later questions may depend on previous questions to answer. You need to provide me with the series of questions as\\\n",
    "the context and I will answer the last question with a multi-step mathematical solution which is a turn program. We use symbols, such as #0,\\\n",
    "#1. Output gives the turn program or steps to calculate the final value. Prompt format:context: {context} questions: {questions} last_question: {last_question}\"\n",
    ")\n",
    "\n",
    "train_instance = train_list[0]\n",
    "\n",
    "\n",
    "prompt_template.format(\n",
    "    context= train_instance['context'],\n",
    "    questions= train_instance['questions'],\n",
    "    last_question= train_instance['last_question']\n",
    "    )\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0.0)\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt_template | model | output_parser\n",
    "chain.invoke({'context':train_instance['context'],\n",
    "            'questions': train_instance['questions'],\n",
    "            'last_question': train_instance['last_question']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few shot prompt & In-Context Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_learning(few_shot_count, test_number):\n",
    "    \"\"\"Function for few shot learning\n",
    "        Input Arguments: few_shot_count: number of few shot examples in the train set\n",
    "                         test_number: test instance number\n",
    "        Output:\n",
    "    \"\"\"\n",
    "    few_shot_examples = train_list[:few_shot_count]\n",
    "    \n",
    "\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"questions\", \"last_question\", \"answer\"],\n",
    "        template=\"context: {context} questions: {questions}last_question: {last_question} \\n{answer}\"\n",
    "    )\n",
    "\n",
    "    few_shot_prompt = FewShotPromptTemplate(\n",
    "        examples=few_shot_examples,\n",
    "        example_prompt=example_prompt,\n",
    "        suffix=\"Instruction: I am a highly intelligent bot. I can have conversations with the user to answer a series of questions.\\\n",
    "Later questions may depend on previous questions to answer. You need to provide me with the series of questions as\\\n",
    "the context and I will answer the last question with a multi-step mathematical solution which is a turn program. We use symbols, such as #0,\\\n",
    "#1. Output gives the turn program or steps to calculate the final value. Prompt format:context: {context} questions: {questions} last_question: {last_question}\",\n",
    "        input_variables=[\"context\", \"questions\", \"last_question\"],\n",
    "    )\n",
    "\n",
    "    test_instance = train_list[test_number]\n",
    "\n",
    "    #print(few_shot_prompt.format(context=test_instance['context'],\n",
    "    #                             questions=test_instance['questions'],\n",
    "    #                             last_question=test_instance['last_question']))\n",
    "\n",
    "    chain = few_shot_prompt | model | output_parser\n",
    "    return chain.invoke({'context':test_instance['context'],\n",
    "                'questions': test_instance['questions'],\n",
    "                'last_question': test_instance['last_question']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate answer for the last question in 6th instance in train data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='wikitable'><tr><td>1</td><td>years ended december 31,</td><td>2016</td><td>2015</td><td>2014</td></tr><tr><td>2</td><td>aes corporation</td><td>$ -50 ( 50 )</td><td>$ -31 ( 31 )</td><td>$ -34 ( 34 )</td></tr><tr><td>3</td><td>chile</td><td>-9 ( 9 )</td><td>-18 ( 18 )</td><td>-30 ( 30 )</td></tr><tr><td>4</td><td>colombia</td><td>-8 ( 8 )</td><td>29</td><td>17</td></tr><tr><td>5</td><td>mexico</td><td>-8 ( 8 )</td><td>-6 ( 6 )</td><td>-14 ( 14 )</td></tr><tr><td>6</td><td>philippines</td><td>12</td><td>8</td><td>11</td></tr><tr><td>7</td><td>united kingdom</td><td>13</td><td>11</td><td>12</td></tr><tr><td>8</td><td>argentina</td><td>37</td><td>124</td><td>66</td></tr><tr><td>9</td><td>other</td><td>-2 ( 2 )</td><td>-10 ( 10 )</td><td>-17 ( 17 )</td></tr><tr><td>10</td><td>total ( 1 )</td><td>$ -15 ( 15 )</td><td>$ 107</td><td>$ 11</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_instance = train_list[10]\n",
    "display(HTML(test_instance['context']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_solution: subtract(-31, -34) = -31 - (-34) = -31 + 34 = 3\n",
      "\n",
      "last_question: and what was that change over the subsequent year, from 2015 to 2016?\n",
      "last_solution: 3\n",
      "subtract(-31, -34)\n",
      "subtract(-31, -34)\n",
      "subtract(-31, -34)\n",
      "subtract(-31, -34)\n",
      "subtract(-31, -34)\n"
     ]
    }
   ],
   "source": [
    "few_shot_learning(0, 10)\n",
    "few_shot_learning(1, 10)\n",
    "few_shot_learning(2, 10)\n",
    "few_shot_learning(3, 10)\n",
    "few_shot_learning(4, 10)\n",
    "few_shot_learning(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and what was that change over the subsequent year, from 2015 to 2016? subtract(-50, -31)\n"
     ]
    }
   ],
   "source": [
    "print(test_instance['last_question'], test_instance['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "With zero-shot learning the model take a correct attempt to answer the last question.\n",
    "\n",
    "When there is only one instance for few-shot learning the model generates an incorrect answer.\n",
    "\n",
    "When only two or three few-shot examples are given, the model may rely heavily on those examples to generate the output, leading to a correct result. In this case the model, might have learned from the additional examples to produce the correct output.\n",
    "\n",
    "In last two cases, despite the correct answer being 'add(2530454, 5923147), divide(#0, 5923147)' based on the input and few-shot examples, the model generated 'add(2530454, 5923147), divide(#2, 5923147)', which does not accurately reflect the provided context. This discrepancy suggests that the model may have 'hallucinated' or generated incorrect information based on its internal processing rather than the actual input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
