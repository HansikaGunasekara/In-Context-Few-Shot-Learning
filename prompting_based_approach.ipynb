{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Context & Few-shot Learning with Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages & environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from IPython.display import HTML\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Let's prepare 15 train instances for the few shot learning & 10 test instances for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CONVFINQA/data/train.json') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_list = []\n",
    "for entry in train_data[:15]:\n",
    "    table = entry['annotation']['amt_table']\n",
    "    question_sequence = entry['annotation']['dialogue_break']\n",
    "    turn_program = entry['annotation']['turn_program']\n",
    "    \n",
    "    follow_up_questions = ''\n",
    "    \n",
    "    for i in range(len(question_sequence)-1):\n",
    "        follow_up_questions += f'Intermediate Question: {question_sequence[i]}\\n'\n",
    "        follow_up_questions += f'Intermediate Solution/Turn Program: {turn_program[i]}\\n'\n",
    "\n",
    "    train_list.append({\n",
    "        'context': table,\n",
    "        'questions': follow_up_questions,\n",
    "        'last_question': question_sequence[-1],\n",
    "        'answer': turn_program[-1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CONVFINQA/data/test_private.json') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "def generate_wiki_table(table_data):\n",
    "    # Initialize the wiki table string\n",
    "    wiki_table = \"<table class='wikitable'>\"\n",
    "\n",
    "    # Iterate over each row in the table data\n",
    "    for row in table_data:\n",
    "        wiki_table += \"<tr>\"\n",
    "        # Iterate over each cell in the row\n",
    "        for cell in row:\n",
    "            wiki_table += f\"<td>{cell}</td>\"\n",
    "        wiki_table += \"</tr>\"\n",
    "\n",
    "    # Close the table tag\n",
    "    wiki_table += \"</table>\"\n",
    "\n",
    "    return wiki_table\n",
    "\n",
    "test_list = []\n",
    "for entry in test_data[:10]:\n",
    "    table = generate_wiki_table(entry['table'])\n",
    "    question_sequence = entry['annotation']['dialogue_break']\n",
    "\n",
    "    follow_up_questions = ''\n",
    "    \n",
    "    for i in range(len(question_sequence)-1):\n",
    "        follow_up_questions += f'Intermediate Question: {question_sequence[i]}\\n'\n",
    "\n",
    "    last_question = question_sequence[-1]\n",
    "\n",
    "    test_list.append({\n",
    "        'context': table,\n",
    "        'questions': follow_up_questions,\n",
    "        'last_question': last_question\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt to Try the Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"context: <table class='wikitable'><tr><td>1</td><td>2008</td><td>year ended june 30 2009 2008</td><td>year ended june 30 2009 2008</td><td>year ended june 30 2009</td></tr><tr><td>2</td><td>net income</td><td>$ 103102</td><td>$ 104222</td><td>$ 104681</td></tr><tr><td>3</td><td>non-cash expenses</td><td>74397</td><td>70420</td><td>56348</td></tr><tr><td>4</td><td>change in receivables</td><td>21214</td><td>-2913 ( 2913 )</td><td>-28853 ( 28853 )</td></tr><tr><td>5</td><td>change in deferred revenue</td><td>21943</td><td>5100</td><td>24576</td></tr><tr><td>6</td><td>change in other assets and liabilities</td><td>-14068 ( 14068 )</td><td>4172</td><td>17495</td></tr><tr><td>7</td><td>net cash from operating activities</td><td>$ 206588</td><td>$ 181001</td><td>$ 174247</td></tr></table>\\nquestions: Intermediate Question: what is the net cash from operating activities in 2009?\\nIntermediate Solution/Turn Program: 206588\\nIntermediate Question: what about in 2008?\\nIntermediate Solution/Turn Program: 181001\\nIntermediate Question: what is the difference?\\nIntermediate Solution/Turn Program: subtract(206588, 181001)\\nlast_question: what percentage change does this represent?\\n\\nTurn Program:\\n1. Calculate the difference: subtract(206588, 181001) = 25587\\n2. Calculate the percentage change: divide(25587, 181001) * 100 = 14.14%\\n\\nTherefore, the percentage change in net cash from operating activities from 2008 to 2009 is 14.14%.\""
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"questions\", \"last_question\"],\n",
    "    template = \"Instruction: I am a highly intelligent bot. I can have conversations with the user to answer a series of questions.\\\n",
    "Later questions may depend on previous questions to answer. You need to provide me with the series of questions as\\\n",
    "the context and I will answer the last question with a multi-step mathematical solution which is a turn program. We use symbols, such as #0,\\\n",
    "#1. Output gives the turn program or steps to calculate the final value. Prompt format:context: {context} questions: {questions} last_question: {last_question}\"\n",
    ")\n",
    "\n",
    "train_instance = train_list[0]\n",
    "\n",
    "\n",
    "prompt_template.format(\n",
    "    context= train_instance['context'],\n",
    "    questions= train_instance['questions'],\n",
    "    last_question= train_instance['last_question']\n",
    "    )\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0.0)\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt_template | model | output_parser\n",
    "chain.invoke({'context':train_instance['context'],\n",
    "            'questions': train_instance['questions'],\n",
    "            'last_question': train_instance['last_question']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few shot prompt & In-Context Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_learning(few_shot_count, test_number):\n",
    "    few_shot_examples = train_list[:few_shot_count]\n",
    "    \n",
    "\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"questions\", \"last_question\", \"answer\"],\n",
    "        template=\"context: {context} questions: {questions}last_question: {last_question} \\n{answer}\"\n",
    "    )\n",
    "\n",
    "    few_shot_prompt = FewShotPromptTemplate(\n",
    "        examples=few_shot_examples,\n",
    "        example_prompt=example_prompt,\n",
    "        suffix=\"Instruction: I am a highly intelligent bot. I can have conversations with the user to answer a series of questions.\\\n",
    "Later questions may depend on previous questions to answer. You need to provide me with the series of questions as\\\n",
    "the context and I will answer the last question with a multi-step mathematical solution which is a turn program. We use symbols, such as #0,\\\n",
    "#1. Output gives the turn program or steps to calculate the final value. Prompt format:context: {context} questions: {questions} last_question: {last_question}\",\n",
    "        input_variables=[\"context\", \"questions\", \"last_question\"],\n",
    "    )\n",
    "\n",
    "    test_instance = train_list[test_number]\n",
    "\n",
    "    #print(few_shot_prompt.format(context=test_instance['context'],\n",
    "    #                             questions=test_instance['questions'],\n",
    "    #                             last_question=test_instance['last_question']))\n",
    "\n",
    "    chain = few_shot_prompt | model | output_parser\n",
    "    print(chain.invoke({'context':test_instance['context'],\n",
    "                'questions': test_instance['questions'],\n",
    "                'last_question': test_instance['last_question']}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate answer for the last question in 6th instance in train data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='wikitable'><tr><td>1</td><td></td><td>shares available for awards</td><td>shares subject to outstanding awards</td></tr><tr><td>2</td><td>2009 global incentive plan</td><td>2322450</td><td>2530454</td></tr><tr><td>3</td><td>2004 stock incentive plan</td><td>-</td><td>5923147</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_instance = train_list[5]\n",
    "display(HTML(test_instance['context']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_solution: divide(5923147, add(2530454, 5923147))\n",
      "subtract(2530454, 5923147), divide(#0, 5923147)\n",
      "add(2530454, 5923147), divide(#0, 5923147)\n",
      "add(2530454, 5923147), divide(#0, 5923147)\n",
      "add(2530454, 5923147), divide(#2, 5923147)\n",
      "add(2530454, 5923147), divide(#2, 5923147)\n"
     ]
    }
   ],
   "source": [
    "few_shot_learning(0, 5)\n",
    "few_shot_learning(1, 5)\n",
    "few_shot_learning(2, 5)\n",
    "few_shot_learning(3, 5)\n",
    "few_shot_learning(4, 5)\n",
    "few_shot_learning(5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "With zero-shot learning the model take a correct attempt to answer the last question.\n",
    "\n",
    "When there is only one instance for few-shot learning the model generates an incorrect answer.\n",
    "\n",
    "When only two or three few-shot examples are given, the model may rely heavily on those examples to generate the output, leading to a correct result. In this case the model, might have learned from the additional examples to produce the correct output.\n",
    "\n",
    "In last two cases, despite the correct answer being 'add(2530454, 5923147), divide(#0, 5923147)' based on the input and few-shot examples, the model generated 'add(2530454, 5923147), divide(#2, 5923147)', which does not accurately reflect the provided context. This discrepancy suggests that the model may have 'hallucinated' or generated incorrect information based on its internal processing rather than the actual input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
