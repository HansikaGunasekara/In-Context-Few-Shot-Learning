{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Context & Few-shot Learning with Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages & environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from IPython.display import HTML\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_community.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Let's prepare 15 train instances for the few shot learning & 10 test instances for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CONVFINQA/data/train.json') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_list = []\n",
    "for entry in train_data[:15]:\n",
    "    table = entry['annotation']['amt_table']\n",
    "    question_sequence = entry['annotation']['dialogue_break']\n",
    "    turn_program = entry['annotation']['turn_program']\n",
    "    \n",
    "    follow_up_questions = ''\n",
    "    \n",
    "    for i in range(len(question_sequence)-1):\n",
    "        follow_up_questions += f'Intermediate Question: {question_sequence[i]}\\n'\n",
    "        follow_up_questions += f'Intermediate Solution/Turn Program: {turn_program[i]}\\n'\n",
    "\n",
    "    train_list.append({\n",
    "        'context': table,\n",
    "        'questions': follow_up_questions,\n",
    "        'last_question': question_sequence[-1],\n",
    "        'answer': turn_program[-1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CONVFINQA/data/test_private.json') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "def generate_wiki_table(table_data):\n",
    "    # Initialize the wiki table string\n",
    "    wiki_table = \"<table class='wikitable'>\"\n",
    "\n",
    "    # Iterate over each row in the table data\n",
    "    for row in table_data:\n",
    "        wiki_table += \"<tr>\"\n",
    "        # Iterate over each cell in the row\n",
    "        for cell in row:\n",
    "            wiki_table += f\"<td>{cell}</td>\"\n",
    "        wiki_table += \"</tr>\"\n",
    "\n",
    "    # Close the table tag\n",
    "    wiki_table += \"</table>\"\n",
    "\n",
    "    return wiki_table\n",
    "\n",
    "test_list = []\n",
    "for entry in test_data[:10]:\n",
    "    table = generate_wiki_table(entry['table'])\n",
    "    question_sequence = entry['annotation']['dialogue_break']\n",
    "\n",
    "    follow_up_questions = ''\n",
    "    \n",
    "    for i in range(len(question_sequence)-1):\n",
    "        follow_up_questions += f'Intermediate Question: {question_sequence[i]}\\n'\n",
    "\n",
    "    last_question = question_sequence[-1]\n",
    "\n",
    "    test_list.append({\n",
    "        'context': table,\n",
    "        'questions': follow_up_questions,\n",
    "        'last_question': last_question\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt to Try the Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'turn program: \\n\\nsubtract(206588, 181001) / 181001 * 100'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"questions\", \"last_question\"],\n",
    "    template = \"Instruction: I am a highly intelligent bot. I can have conversations with the user to answer a series of questions.\\\n",
    "Later questions may depend on previous questions to answer. You need to provide me with the series of questions as\\\n",
    "the context and I will answer the last question with a multi-step mathematical solution which is a turn program. We use symbols, such as #0,\\\n",
    "#1. Output gives the turn program or steps to calculate the final value. Prompt format:context: {context} questions: {questions} last_question: {last_question}\"\n",
    ")\n",
    "\n",
    "train_instance = train_list[0]\n",
    "\n",
    "\n",
    "prompt_template.format(\n",
    "    context= train_instance['context'],\n",
    "    questions= train_instance['questions'],\n",
    "    last_question= train_instance['last_question']\n",
    "    )\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0.0)\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt_template | model | output_parser\n",
    "chain.invoke({'context':train_instance['context'],\n",
    "            'questions': train_instance['questions'],\n",
    "            'last_question': train_instance['last_question']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few shot prompt & In-Context Learning\n",
    "Let's observe the zero-shot & few-shot learning of the model for differnt counts of few-shot learning attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_learning(few_shot_count, test_number):\n",
    "    \"\"\"Function for few shot learning\n",
    "        Input Arguments: few_shot_count: number of few shot examples in the train set\n",
    "                         test_number: test instance number\n",
    "        Output:\n",
    "    \"\"\"\n",
    "    few_shot_examples = train_list[:few_shot_count]\n",
    "    \n",
    "\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"questions\", \"last_question\", \"answer\"],\n",
    "        template=\"context: {context} questions: {questions}last_question: {last_question} \\n{answer}\"\n",
    "    )\n",
    "\n",
    "    few_shot_prompt = FewShotPromptTemplate(\n",
    "        examples=few_shot_examples,\n",
    "        example_prompt=example_prompt,\n",
    "        suffix=\"Instruction: I am a highly intelligent bot. I can have conversations with the user to answer a series of questions.\\\n",
    "Later questions may depend on previous questions to answer. You need to provide me with the series of questions as\\\n",
    "the context and I will answer the last question with a multi-step mathematical solution which is a turn program. We use symbols, such as #0,\\\n",
    "#1. Output gives the turn program or steps to calculate the final value. Prompt format:context: {context} questions: {questions} last_question: {last_question}\",\n",
    "        input_variables=[\"context\", \"questions\", \"last_question\"],\n",
    "    )\n",
    "\n",
    "    test_instance = train_list[test_number]\n",
    "\n",
    "    #print(few_shot_prompt.format(context=test_instance['context'],\n",
    "    #                             questions=test_instance['questions'],\n",
    "    #                             last_question=test_instance['last_question']))\n",
    "\n",
    "    chain = few_shot_prompt | model | output_parser\n",
    "    with get_openai_callback() as cb:\n",
    "        output = chain.invoke(\n",
    "            {'context':test_instance['context'],\n",
    "            'questions': test_instance['questions'],\n",
    "            'last_question': test_instance['last_question']}\n",
    "        )\n",
    "        #print(output)\n",
    "        #print(cb)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting Based approach with GPT-3.5 Model\n",
    "Let's iterate through 6 instances applying few-shot learning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_list = [[\n",
    "    \"test instance\", \"last question\", \"actual_answer\", \"with 0 shot\",\n",
    "    \"with 1 shot\", \"with 2 shot\", \"with 3 shot\",\n",
    "    \"with 4 shot\", \"with 5 shot\"]]\n",
    "for instance_num in range(5, 11):\n",
    "    test_instance = train_list[instance_num]\n",
    "    test_instance_answer = [\n",
    "        instance_num,\n",
    "        test_instance['last_question'],\n",
    "        test_instance['answer']\n",
    "    ]\n",
    "    for few_shot_count in range(0, 6):\n",
    "        test_instance_answer.append(\n",
    "            few_shot_learning(few_shot_count, instance_num))\n",
    "    answer_list.append(test_instance_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='wikitable'><tr><td>test instance</td><td>last question</td><td>actual_answer</td><td>with 0 shot</td><td>with 1 shot</td><td>with 2 shot</td><td>with 3 shot</td><td>with 4 shot</td><td>with 5 shot</td></tr><tr><td>5</td><td>what proportion does this represent?</td><td>add(2530454, 5923147), divide(5923147, #0)</td><td>last_solution: divide(5923147, add(2530454, 5923147))</td><td>subtract(2530454, 5923147), divide(#0, 5923147)</td><td>add(2530454, 5923147), divide(#0, 5923147)</td><td>add(2530454, 5923147), divide(#0, 5923147)</td><td>add(2530454, 5923147), divide(#2, 5923147)</td><td>add(2530454, 5923147), divide(#2, 5923147)</td></tr><tr><td>6</td><td>what was the percent change?</td><td>subtract(3.7, 3.2), divide(#0, 3.2)</td><td>To calculate the percent change, you can use the following formula:\n",
       "\n",
       "percent change = ((new value - old value) / old value) * 100\n",
       "\n",
       "First, calculate the new value by adding the net change in value of litigation reserves during 2012 to the value of litigation reserves at the start of 2012:\n",
       "\n",
       "new value = 3.2 + (3.7 - 3.2)\n",
       "\n",
       "new value = 3.2 + 0.5\n",
       "\n",
       "new value = 3.7\n",
       "\n",
       "Next, plug the values into the formula:\n",
       "\n",
       "percent change = ((3.7 - 3.2) / 3.2) * 100\n",
       "\n",
       "percent change = (0.5 / 3.2) * 100\n",
       "\n",
       "percent change = 0.15625 * 100\n",
       "\n",
       "percent change = 15.625%\n",
       "\n",
       "Therefore, the percent change in the value of litigation reserves during 2012 was 15.625%.</td><td>subtract(3.7, 3.2), divide(subtract(3.7, 3.2), 3.2)</td><td>subtract(3.7, 3.2), divide(#0, 3.2)</td><td>subtract(3.7, 3.2), divide(#0, 3.2)</td><td>subtract(3.7, 3.2), divide(#0, 3.2)</td><td>subtract(3.7, 3.2), divide(#0, 3.2)</td></tr><tr><td>7</td><td>and the percentage change of this value?</td><td>subtract(118, 102), divide(#0, 102)</td><td>Intermediate Solution/Turn Program:\n",
       "#0: subtract(118, 102)\n",
       "#1: divide(subtract(118, 102), 102)\n",
       "#2: multiply(divide(subtract(118, 102), 102), 100)\n",
       "\n",
       "Therefore, the percentage change of the company's warranty liability between 2011 and 2012 is 15.686%.</td><td>subtract(118, 102), divide(#0, 102)</td><td>subtract(118, 102), divide(#0, 102)</td><td>subtract(118, 102), divide(#0, 102)</td><td>subtract(118, 102), divide(#0, 102), multiply(#1, 100)</td><td>subtract(118, 102), divide(#0, 102)</td></tr><tr><td>8</td><td>what is the sum divided by total obligations due?</td><td>add(27729, 45161), divide(#0, 317105)</td><td>Turn Program:\n",
       "add(27729, 45161) = 72890\n",
       "divide(72890, 317105) = 0.2299</td><td>subtract(27729, 45161), divide(#0, 317105)</td><td>add(27729, 45161), divide(#0, 317105)</td><td>add(27729, 45161), divide(#0, 317105)</td><td>add(27729, 45161), divide(#0, 317105)</td><td>add(27729, 45161), divide(#2, 317105)</td></tr><tr><td>9</td><td>including the year of 2011, what would then be the total sum capitalized in the three years, in millions?</td><td>add(4.5, 4.1), add(#0, 3.4)</td><td>last_solution: add(add(4.5, 4.1), 1.7) = 10.3</td><td>add(#0, 4.5)</td><td>add(#0, 4.5)</td><td>add(4.5, 4.1), add(#0, 17.4)</td><td>add(4.5, 4.1, 4.5)</td><td>add(4.5, 4.1) + 3.4</td></tr><tr><td>10</td><td>and what was that change over the subsequent year, from 2015 to 2016?</td><td>subtract(-50, -31)</td><td>last_solution: subtract(-31, -34) = -31 - (-34) = -31 + 34 = 3\n",
       "\n",
       "last_question: and what was that change over the subsequent year, from 2015 to 2016?\n",
       "last_solution: 3 + (-50) = -47</td><td>subtract(-31, -34)</td><td>subtract(-31, -34)</td><td>subtract(-31, -34)</td><td>subtract(-31, -34)</td><td>subtract(-31, -34)</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(generate_wiki_table(answer_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "Paper mentions that, **GPT-3.5 can do simple calculations by itself**. From the above table we can see that **out of the 6 instances the model can caclulate the answer itself for 3 instances**.\n",
    "\n",
    "The paper explains, **how the model demonstrate how the model often make errors for the quesitons with references to the previous conversation context.** From the above table we can see such a scenario in the 10th test instance.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
